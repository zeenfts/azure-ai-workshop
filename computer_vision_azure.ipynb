{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "computer-vision-azure.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Computer Vision in Azure\n",
        "\n",
        "[<sup>source</sup>](https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/quickstarts-sdk/image-analysis-client-library?tabs=visual-studio&pivots=programming-language-python)"
      ],
      "metadata": {
        "id": "d_Tult4coR8c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF45_lXoeh37"
      },
      "outputs": [],
      "source": [
        "!pip install -U azure-cognitiveservices-vision-computervision\n",
        "!pip install -U pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "from array import array\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "import time"
      ],
      "metadata": {
        "id": "9q8UCSqwoP4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subscription_key = \"PASTE_YOUR_COMPUTER_VISION_SUBSCRIPTION_KEY_HERE\"\n",
        "endpoint = \"PASTE_YOUR_COMPUTER_VISION_ENDPOINT_HERE\"\n",
        "\n",
        "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
      ],
      "metadata": {
        "id": "h8jgMwJPoXAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "  \n",
        "remote_image_url = \"https://raw.githubusercontent.com/zeenfts/azure-ai-workshop/main/img/woodlog-lake.jpg\"\n",
        "\n",
        "# # Special for object detections\n",
        "# remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
        "# remote_image_url = \"https://raw.githubusercontent.com/MicrosoftLearning/AI-900-AIFundamentals/main/data/vision/produce.jpg\"\n",
        "\n",
        "img_name = remote_image_url.split('/')[-1]\n",
        "\n",
        "urllib.request.urlretrieve(remote_image_url, img_name)\n",
        "\n",
        "# # local image\n",
        "# img_name = 'img/sunset-traffic.jpg'\n",
        "  \n",
        "img = Image.open(img_name)\n",
        "img.show()"
      ],
      "metadata": {
        "id": "SXcZKISBoY9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Describe an Image"
      ],
      "metadata": {
        "id": "Azm07a-HoZ9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Describe an Image - remote\n",
        "This example describes the contents of an image with the confidence score.\n",
        "'''\n",
        "print(\"===== Describe an image - remote =====\")\n",
        "# Call API\n",
        "description_results = computervision_client.describe_image(remote_image_url )\n",
        "\n",
        "# Get the captions (descriptions) from the response, with confidence level\n",
        "print(\"Description of remote image: \")\n",
        "if (len(description_results.captions) == 0):\n",
        "    print(\"No description detected.\")\n",
        "else:\n",
        "    for caption in description_results.captions:\n",
        "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
      ],
      "metadata": {
        "id": "j4PSUw4jodSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objects Detection"
      ],
      "metadata": {
        "id": "6q2ft6cLGgls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Detect Objects - remote\n",
        "This example detects different kinds of objects with bounding boxes in a remote image.\n",
        "'''\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img_arr = np.array(img)\n",
        "\n",
        "print(\"===== Detect Objects - remote =====\")\n",
        "\n",
        "# Call API with URL\n",
        "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url)\n",
        "\n",
        "# Print detected objects results with bounding boxes\n",
        "print(\"Detecting objects in remote image:\")\n",
        "if len(detect_objects_results_remote.objects) == 0:\n",
        "    print(\"No objects detected.\")\n",
        "else:\n",
        "    for obj in detect_objects_results_remote.objects:\n",
        "        cv2.rectangle(\n",
        "            img_arr,\n",
        "            (obj.rectangle.x, obj.rectangle.y),\n",
        "            (obj.rectangle.x + obj.rectangle.w, obj.rectangle.y + obj.rectangle.h),\n",
        "            (0,255,0),3\n",
        "            )\n",
        "\n",
        "Image.fromarray(img_arr)"
      ],
      "metadata": {
        "id": "5_7jxQcSGg0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categorize an Image"
      ],
      "metadata": {
        "id": "6MxrbDcUofaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Categorize an Image - remote\n",
        "This example extracts (general) categories from a remote image with a confidence score.\n",
        "'''\n",
        "print(\"===== Categorize an image - remote =====\")\n",
        "# Select the visual feature(s) you want.\n",
        "remote_image_features = [\"categories\"]\n",
        "# Call API with URL and features\n",
        "categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
        "\n",
        "# Print results with confidence score\n",
        "print(\"Categories from remote image: \")\n",
        "if (len(categorize_results_remote.categories) == 0):\n",
        "    print(\"No categories detected.\")\n",
        "else:\n",
        "    for category in categorize_results_remote.categories:\n",
        "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
      ],
      "metadata": {
        "id": "W_akIUTxoim-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Tagging"
      ],
      "metadata": {
        "id": "P9jrOk3aokOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Tag an Image - remote\n",
        "This example returns a tag (key word) for each thing in the image.\n",
        "'''\n",
        "print(\"===== Tag an image - remote =====\")\n",
        "# Call API with remote image\n",
        "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
        "\n",
        "# Print results with confidence score\n",
        "print(\"Tags in the remote image: \")\n",
        "if (len(tags_result_remote.tags) == 0):\n",
        "    print(\"No tags detected.\")\n",
        "else:\n",
        "    for tag in tags_result_remote.tags:\n",
        "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))"
      ],
      "metadata": {
        "id": "mBz10HUoomtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detect Image Colors"
      ],
      "metadata": {
        "id": "o_bHwHFTooYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Detect Color - remote\n",
        "This example detects the different aspects of its color scheme in a remote image.\n",
        "'''\n",
        "print(\"===== Detect Color - remote =====\")\n",
        "# Select the feature(s) you want\n",
        "remote_image_features = [\"color\"]\n",
        "# Call API with URL and features\n",
        "detect_color_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
        "\n",
        "# Print results of color scheme\n",
        "print(\"Getting color scheme of the remote image: \")\n",
        "print(\"Is black and white: {}\".format(detect_color_results_remote.color.is_bw_img))\n",
        "print(\"Accent color: {}\".format(detect_color_results_remote.color.accent_color))\n",
        "print(\"Dominant background color: {}\".format(detect_color_results_remote.color.dominant_color_background))\n",
        "print(\"Dominant foreground color: {}\".format(detect_color_results_remote.color.dominant_color_foreground))\n",
        "print(\"Dominant colors: {}\".format(detect_color_results_remote.color.dominant_colors))"
      ],
      "metadata": {
        "id": "Z6qQID6Poqcz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}